# Default values for canary services.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

### Default values for sample-app.
appName: sample-app
namespace: default
env: testdapne2


### Gateway, Virtual Service of istio Config
host: sample-app.namejsjeong.co.kr


### Spring env Config
envVars:
  - name: spring.profiles.active
    value: testdapne2


### Pod Config
replicaCount: 5

podAnnotations: 
  traffic.sidecar.istio.io/excludeOutboundPorts: "3310,7379"


### HPA Config
autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80


### IRSA Config 
serviceAccount:
  enabled: false
  # Specifies whether a service account should be created
  create: false
  # Annotations to add to the service account
  annotations:
    {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: "test-sa"


### Pod, Service ports Config
ports:
- name: http
  port: 80
  targetPort: 8080
  protocol: TCP

service:
  type: ClusterIP
  port: 80


### Pod LifeCycle Config
readinessProbe:
  enabled: false
livenessProbe:
  enabled: true
  httpGet:
  path: /actuator/health
  port: 8080
  initialDelaySeconds: 300
  periodSeconds: 10   # default value
  timeoutSeconds: 1   # default value
  successThreshold: 1 # default value
  failureThreshold: 3 # default value


### Pod QoS Config
resources: 
  enabled: true
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  limits:
    cpu: 200m
    memory: 1Gi
  requests:
    cpu: 200m
    memory: 1Gi


### Pod deployment strategies Config
nodeSelector: {}

tolerations: []

affinity: {}


### Pod Security Config
podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000


### Ingress Config
ingress:
  enabled: false
  className: ""
  annotations:
    alb.ingress.kubernetes.io/actions.ssl-redirect: >-
      {"Type": "redirect", "RedirectConfig":{ "Protocol": "HTTPS", "Port":
      "443", "StatusCode": "HTTP_301"}}
    alb.ingress.kubernetes.io/certificate-arn: >-
      arn:aws:acm:ap-northeast-2:123123123:certificate/test
    alb.ingress.kubernetes.io/healthcheck-path: /
    alb.ingress.kubernetes.io/healthcheck-protocol: HTTP
    alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}, {"HTTPS":443}]'
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/ssl-policy: ELBSecurityPolicy-TLS-1-2-2017-01
    alb.ingress.kubernetes.io/security-groups: sg-123123
    external-dns.alpha.kubernetes.io/hostname: "sample-app.namejsjeong.co.kr"
  hosts:
    - http:
      paths:
        - backend:
            service:
              name: istio-ingressgateway
              port:
                number: 80
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

# datadog Config
datadog:
  enabled: true


# Canary Deployment Strategy
canary:
  # deployment steps
  steps:
    - setWeight: 20
    - pause: {}
    - setWeight: 40
    - pause: {duration: 30s}
    - setWeight: 60
    - pause: {duration: 30s}
    - setWeight: 80
    - pause: {duration: 30s}
    - setWeight: 100
    - pause: {duration: 30s}
  #  metric analysis to automate update promotion or rollback
  analysis:
    metrics:
      - name: success-rate
        initialDelay: 300s
        interval: 20s
        successCondition: result[0] > 0.90
        provider:
          prometheus:
            address: http://prometheus.istio-system:9090
            query: |
              sum(irate(
                istio_requests_total{reporter="source",destination_service=~"{{args.service}}.{{args.namespace}}.svc.cluster.local",response_code!~"5.*"}[480s]
              )) /
              sum(irate(
                istio_requests_total{reporter="source",destination_service=~"{{args.service}}.{{args.namespace}}.svc.cluster.local"}[480s]
              ))
